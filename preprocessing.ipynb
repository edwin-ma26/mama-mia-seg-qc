{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71be39e0-114b-487a-a654-d2fbd56675fb",
   "metadata": {},
   "source": [
    "# N4 Bias + Denoise + Resample + Affine Updating + Padding (most samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6175f-84ae-48ef-b79f-1414d9e8e3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] Starting batch processing...\n",
      "\n",
      "[PROCESSING] images\\DUKE_001\\duke_001_0001.nii.gz\n",
      "[INFO] Image shape: (448, 448, 160), spacing: (0.8035714, 0.8035714, 1.1)\n",
      "[STEP] Running N4 bias correction...\n",
      "[DONE] N4 bias correction complete.\n",
      "[STEP] Running denoising...\n",
      "[DONE] Denoising complete.\n",
      "[INFO] Resampling with zoom factors: [0.8035714  0.8035714  1.10000002], order=1\n",
      "[INFO] Padding shape (360, 360, 176) → (384, 384, 192)\n",
      "[INFO] Padding widths: [(12, 12), (12, 12), (8, 8)]\n",
      "[✅ SAVED] Image: images\\DUKE_001\\duke_001_0001_n4_denoised_resampled_padded.nii.gz\n",
      "[STEP] Processing mask: segmentations/automatic\\DUKE_001.nii.gz\n",
      "[INFO] Resampling with zoom factors: [0.8035714  0.8035714  1.10000002], order=0\n",
      "[INFO] Padding shape (360, 360, 176) → (384, 384, 192)\n",
      "[INFO] Padding widths: [(12, 12), (12, 12), (8, 8)]\n",
      "[✅ SAVED] Mask: segmentations/automatic\\DUKE_001_processed.nii.gz\n",
      "\n",
      "[PROCESSING] images\\DUKE_002\\duke_002_0001.nii.gz\n",
      "[INFO] Image shape: (512, 512, 142), spacing: (0.5859, 0.5859, 1.3000007)\n",
      "[STEP] Running N4 bias correction...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# ---- Configuration ----\n",
    "images_root = \"../images\"\n",
    "masks_root = \"../segmentations/automatic\"\n",
    "target_spacing = [1.0, 1.0, 1.0]\n",
    "target_shape = (384, 384, 192)\n",
    "\n",
    "# ---- Utility Functions ----\n",
    "def update_affine_for_new_spacing(original_affine, new_spacing):\n",
    "    new_affine = original_affine.copy()\n",
    "    new_affine[:3, :3] = np.diag(new_spacing)\n",
    "    return new_affine\n",
    "\n",
    "def resample_image(img_np, orig_spacing, new_spacing, order=1):\n",
    "    zoom_factors = np.array(orig_spacing) / np.array(new_spacing)\n",
    "    print(f\"[INFO] Resampling with zoom factors: {zoom_factors}, order={order}\")\n",
    "    return zoom(img_np, zoom=zoom_factors, order=order)\n",
    "\n",
    "def n4_bias_correction(image_np):\n",
    "    print(\"[STEP] Running N4 bias correction...\")\n",
    "    sitk_image = sitk.GetImageFromArray(image_np.astype(np.float32))\n",
    "    mask_image = sitk.OtsuThreshold(sitk_image, 0, 1, 200)\n",
    "    corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    corrected = corrector.Execute(sitk_image, mask_image)\n",
    "    print(\"[DONE] N4 bias correction complete.\")\n",
    "    return sitk.GetArrayFromImage(corrected)\n",
    "\n",
    "def denoise_image(image_np):\n",
    "    print(\"[STEP] Running denoising...\")\n",
    "    sitk_image = sitk.GetImageFromArray(image_np.astype(np.float32))\n",
    "    denoised = sitk.CurvatureFlow(image1=sitk_image, timeStep=0.125, numberOfIterations=5)\n",
    "    print(\"[DONE] Denoising complete.\")\n",
    "    return sitk.GetArrayFromImage(denoised)\n",
    "\n",
    "def pad_to_shape(volume, target_shape):\n",
    "    print(f\"[INFO] Padding shape {volume.shape} → {target_shape}\")\n",
    "    pad_widths = []\n",
    "    for dim_size, target in zip(volume.shape, target_shape):\n",
    "        if dim_size > target:\n",
    "            print(f\"[WARNING] Skipping — dimension {dim_size} exceeds target {target}\")\n",
    "            return None\n",
    "        pad_total = target - dim_size\n",
    "        pad_before = pad_total // 2\n",
    "        pad_after = pad_total - pad_before\n",
    "        pad_widths.append((pad_before, pad_after))\n",
    "    print(f\"[INFO] Padding widths: {pad_widths}\")\n",
    "    return np.pad(volume, pad_widths, mode='constant', constant_values=0)\n",
    "\n",
    "# ---- Main Loop ----\n",
    "print(\"[INIT] Starting batch processing (patients 101–200)...\")\n",
    "\n",
    "all_patient_ids = sorted(os.listdir(images_root))\n",
    "processed_count = 0\n",
    "\n",
    "# Process only patients 101–200 (index 100 to 199)\n",
    "for patient_id in all_patient_ids[100:200]:\n",
    "    patient_folder = os.path.join(images_root, patient_id)\n",
    "    if not os.path.isdir(patient_folder):\n",
    "        continue\n",
    "\n",
    "    for fname in os.listdir(patient_folder):\n",
    "        if fname.startswith(\"DUKE_\") and fname.endswith(\"0001.nii.gz\"):\n",
    "            input_path = os.path.join(patient_folder, fname)\n",
    "            base_name = fname.replace(\".nii.gz\", \"\")\n",
    "            output_image_path = os.path.join(patient_folder, f\"{base_name}_n4_denoised_resampled_padded.nii.gz\")\n",
    "\n",
    "            mask_input_path = os.path.join(masks_root, f\"{patient_id}.nii.gz\")\n",
    "            mask_output_path = os.path.join(masks_root, f\"{patient_id}_processed.nii.gz\")\n",
    "\n",
    "            print(f\"\\n[PROCESSING] {input_path}\")\n",
    "\n",
    "            try:\n",
    "                # Load and preprocess image\n",
    "                img_nib = nib.load(input_path)\n",
    "                img_np = img_nib.get_fdata()\n",
    "                orig_affine = img_nib.affine\n",
    "                orig_spacing = img_nib.header.get_zooms()[:3]\n",
    "                print(f\"[INFO] Image shape: {img_np.shape}, spacing: {orig_spacing}\")\n",
    "\n",
    "                img_n4 = n4_bias_correction(img_np)\n",
    "                img_denoised = denoise_image(img_n4)\n",
    "                img_resampled = resample_image(img_denoised, orig_spacing, target_spacing)\n",
    "\n",
    "                padded_img = pad_to_shape(img_resampled, target_shape)\n",
    "                if padded_img is None:\n",
    "                    print(\"[SKIPPED] Image too large to pad.\")\n",
    "                    break\n",
    "\n",
    "                new_affine = update_affine_for_new_spacing(orig_affine, target_spacing)\n",
    "                nib.save(nib.Nifti1Image(padded_img, new_affine), output_image_path)\n",
    "                print(f\"[✅ SAVED] Image: {output_image_path}\")\n",
    "\n",
    "                # --- Process mask if it exists ---\n",
    "                if os.path.exists(mask_input_path):\n",
    "                    print(f\"[STEP] Processing mask: {mask_input_path}\")\n",
    "                    mask_nib = nib.load(mask_input_path)\n",
    "                    mask_np = mask_nib.get_fdata()\n",
    "                    mask_spacing = mask_nib.header.get_zooms()[:3]\n",
    "\n",
    "                    mask_resampled = resample_image(mask_np, mask_spacing, target_spacing, order=0)\n",
    "                    padded_mask = pad_to_shape(mask_resampled, target_shape)\n",
    "                    if padded_mask is None:\n",
    "                        print(\"[SKIPPED] Mask too large to pad.\")\n",
    "                        break\n",
    "\n",
    "                    nib.save(nib.Nifti1Image(padded_mask, new_affine), mask_output_path)\n",
    "                    print(f\"[✅ SAVED] Mask: {mask_output_path}\")\n",
    "                else:\n",
    "                    print(f\"[WARNING] Mask not found for {patient_id}, skipping mask.\")\n",
    "\n",
    "                processed_count += 1\n",
    "                break  # Move to next patient after processing one image\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[❌ ERROR] Failed processing {input_path}: {e}\")\n",
    "                break\n",
    "\n",
    "print(f\"\\n[COMPLETE] Processed {processed_count} patients (101–200).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e083c653-8e40-41a9-bd41-c424cce61c5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# N4 Bias + Denoise + Resample + Affine Updating + Isotropic Resizing + Padding (skipped samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17086841-10f3-4ff9-bb86-939777a6c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# Paths\n",
    "images_root = \"../images\"\n",
    "masks_root = \"../segmentations/automatic\"\n",
    "target_shape = (384, 384, 192)\n",
    "missing_patients = [\n",
    "    \"DUKE_012\", \"DUKE_028\", \"DUKE_046\", \"DUKE_051\", \"DUKE_069\", \"DUKE_071\", \"DUKE_082\", \"DUKE_086\", \"DUKE_090\",\n",
    "    \"DUKE_097\", \"DUKE_107\", \"DUKE_116\", \"DUKE_117\", \"DUKE_141\", \"DUKE_168\", \"DUKE_178\", \"DUKE_183\", \"DUKE_185\",\n",
    "    \"DUKE_228\", \"DUKE_236\", \"DUKE_240\", \"DUKE_250\", \"DUKE_253\", \"DUKE_285\", \"DUKE_290\", \"DUKE_298\", \"DUKE_307\",\n",
    "    \"DUKE_321\", \"DUKE_346\", \"DUKE_350\", \"DUKE_360\", \"DUKE_368\", \"DUKE_385\", \"DUKE_406\", \"DUKE_407\", \"DUKE_412\",\n",
    "    \"DUKE_420\", \"DUKE_438\", \"DUKE_444\", \"DUKE_465\", \"DUKE_470\", \"DUKE_474\", \"DUKE_482\", \"DUKE_525\", \"DUKE_527\",\n",
    "    \"DUKE_535\", \"DUKE_543\", \"DUKE_562\", \"DUKE_567\", \"DUKE_610\", \"DUKE_612\", \"DUKE_615\", \"DUKE_623\", \"DUKE_633\",\n",
    "    \"DUKE_645\", \"DUKE_660\", \"DUKE_662\", \"DUKE_666\", \"DUKE_687\", \"DUKE_688\", \"DUKE_697\", \"DUKE_717\", \"DUKE_724\",\n",
    "    \"DUKE_751\", \"DUKE_754\", \"DUKE_774\", \"DUKE_775\", \"DUKE_776\", \"DUKE_778\", \"DUKE_780\", \"DUKE_789\", \"DUKE_792\",\n",
    "    \"DUKE_816\", \"DUKE_817\", \"DUKE_873\", \"DUKE_874\", \"DUKE_886\", \"DUKE_916\", \"DUKE_917\"\n",
    "]\n",
    "\n",
    "def save_image(image, path):\n",
    "    sitk.WriteImage(image, path)\n",
    "\n",
    "def sitk_to_numpy(image):\n",
    "    return sitk.GetArrayFromImage(image), image.GetSpacing(), image.GetOrigin(), image.GetDirection()\n",
    "\n",
    "def numpy_to_sitk(np_array, spacing, origin, direction):\n",
    "    image = sitk.GetImageFromArray(np_array)\n",
    "    image.SetSpacing(spacing)\n",
    "    image.SetOrigin(origin)\n",
    "    image.SetDirection(direction)\n",
    "    return image\n",
    "\n",
    "def resize_image_to_fit(np_image, target_shape):\n",
    "    current_shape = np_image.shape\n",
    "    scale = min(t / c for t, c in zip(target_shape, current_shape))\n",
    "    zoom_factors = [scale] * len(current_shape)\n",
    "    resized = zoom(np_image, zoom_factors, order=1)\n",
    "    return resized\n",
    "\n",
    "for patient_id in missing_patients:\n",
    "    try:\n",
    "        image_path = os.path.join(images_root, patient_id, f\"{patient_id}_0001.nii.gz\")\n",
    "        mask_path = os.path.join(masks_root, f\"{patient_id}_processed.nii.gz\")\n",
    "\n",
    "        if not os.path.exists(image_path) or not os.path.exists(mask_path):\n",
    "            print(f\"[SKIP] {patient_id}: Missing image or mask.\")\n",
    "            continue\n",
    "\n",
    "        base_dir = os.path.join(images_root, patient_id)\n",
    "\n",
    "        # Load image and mask\n",
    "        image = sitk.ReadImage(image_path)\n",
    "        mask = sitk.ReadImage(mask_path)\n",
    "\n",
    "        # Step 1: N4 bias correction\n",
    "        otsu_mask = sitk.OtsuThreshold(image, 0, 1, 200)\n",
    "        corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "        image_n4 = corrector.Execute(image, otsu_mask)\n",
    "        save_image(image_n4, os.path.join(base_dir, f\"{patient_id}_0001_n4.nii.gz\"))\n",
    "\n",
    "        # Step 2: Denoising\n",
    "        image_denoised = sitk.CurvatureFlow(image1=image_n4, timeStep=0.125, numberOfIterations=5)\n",
    "        save_image(image_denoised, os.path.join(base_dir, f\"{patient_id}_0001_n4_denoised.nii.gz\"))\n",
    "\n",
    "        # Step 3: Resampling image and mask to isotropic 1mm\n",
    "        def resample(img, interpolator):\n",
    "            spacing = img.GetSpacing()\n",
    "            size = img.GetSize()\n",
    "            new_spacing = [1.0, 1.0, 1.0]\n",
    "            new_size = [int(round(sz * spc / nsp)) for sz, spc, nsp in zip(size, spacing, new_spacing)]\n",
    "            resampler = sitk.ResampleImageFilter()\n",
    "            resampler.SetOutputSpacing(new_spacing)\n",
    "            resampler.SetSize(new_size)\n",
    "            resampler.SetOutputOrigin(img.GetOrigin())\n",
    "            resampler.SetOutputDirection(img.GetDirection())\n",
    "            resampler.SetInterpolator(interpolator)\n",
    "            return resampler.Execute(img)\n",
    "\n",
    "        image_resampled = resample(image_denoised, sitk.sitkLinear)\n",
    "        mask_resampled = resample(mask, sitk.sitkNearestNeighbor)\n",
    "        save_image(image_resampled, os.path.join(base_dir, f\"{patient_id}_0001_n4_denoised_resampled.nii.gz\"))\n",
    "        save_image(mask_resampled, os.path.join(base_dir, f\"{patient_id}_processed_resampled.nii.gz\"))\n",
    "\n",
    "        # Step 4: Resize to fit inside target shape\n",
    "        def resize_sitk_image(img, order):\n",
    "            np_img, spacing, origin, direction = sitk_to_numpy(img)\n",
    "            resized_np = resize_image_to_fit(np_img, target_shape)\n",
    "            return numpy_to_sitk(resized_np, [1.0, 1.0, 1.0], origin, direction)\n",
    "\n",
    "        image_resized = resize_sitk_image(image_resampled, order=1)\n",
    "        mask_resized = resize_sitk_image(mask_resampled, order=0)\n",
    "        save_image(image_resized, os.path.join(base_dir, f\"{patient_id}_0001_n4_denoised_resampled_resized.nii.gz\"))\n",
    "        save_image(mask_resized, os.path.join(base_dir, f\"{patient_id}_processed_resampled_resized.nii.gz\"))\n",
    "\n",
    "        print(f\"[DONE] Processed {patient_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed on {patient_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba42b65-110c-43b6-b9f2-e2d0c0226cce",
   "metadata": {},
   "source": [
    "# Miscellaneous Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba8d2dc-0be9-40c3-a690-c1fe03238d78",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## N4 Bias + Denoise + Resample + Affine Updating (1 sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9dd6d6b-045f-4c8b-9077-3913dac8a202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STEP] N4 bias correction...\n",
      "[STEP] Denoising...\n",
      "[STEP] Resampling...\n",
      "[DONE] Saved resampled image with updated spacing to images/DUKE_313/duke_313_n4_denoised_resampled_fixed.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# ---- Configuration ----\n",
    "input_path = \"images/DUKE_313/duke_313_0001.nii.gz\"\n",
    "output_path = \"images/DUKE_313/duke_313_n4_denoised_resampled_fixed.nii.gz\"\n",
    "target_spacing = [1.0, 1.0, 1.0]\n",
    "\n",
    "# ---- Affine Update Function ----\n",
    "def update_affine_for_new_spacing(original_affine, new_spacing):\n",
    "    new_affine = original_affine.copy()\n",
    "    new_affine[:3, :3] = np.diag(new_spacing)\n",
    "    return new_affine\n",
    "\n",
    "# ---- Resampling Function ----\n",
    "def resample_image(img_np, orig_spacing, new_spacing, order=1):\n",
    "    zoom_factors = np.array(orig_spacing) / np.array(new_spacing)\n",
    "    return zoom(img_np, zoom=zoom_factors, order=order)\n",
    "\n",
    "# ---- N4 Bias Correction ----\n",
    "def n4_bias_correction(image_np):\n",
    "    sitk_image = sitk.GetImageFromArray(image_np.astype(np.float32))\n",
    "    mask_image = sitk.OtsuThreshold(sitk_image, 0, 1, 200)\n",
    "    corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    corrected = corrector.Execute(sitk_image, mask_image)\n",
    "    return sitk.GetArrayFromImage(corrected)\n",
    "\n",
    "# ---- Denoising ----\n",
    "def denoise_image(image_np):\n",
    "    sitk_image = sitk.GetImageFromArray(image_np.astype(np.float32))\n",
    "    denoised = sitk.CurvatureFlow(image1=sitk_image, timeStep=0.125, numberOfIterations=5)\n",
    "    return sitk.GetArrayFromImage(denoised)\n",
    "\n",
    "# ---- Load Original Image ----\n",
    "img_nib = nib.load(input_path)\n",
    "img_np = img_nib.get_fdata()\n",
    "orig_affine = img_nib.affine\n",
    "orig_spacing = img_nib.header.get_zooms()[:3]\n",
    "\n",
    "# ---- Apply N4 Correction ----\n",
    "print(\"[STEP] N4 bias correction...\")\n",
    "img_n4 = n4_bias_correction(img_np)\n",
    "\n",
    "# ---- Apply Denoising ----\n",
    "print(\"[STEP] Denoising...\")\n",
    "img_denoised = denoise_image(img_n4)\n",
    "\n",
    "# ---- Apply Resampling ----\n",
    "print(\"[STEP] Resampling...\")\n",
    "resampled_np = resample_image(img_denoised, orig_spacing, target_spacing)\n",
    "\n",
    "# ---- Update Affine ----\n",
    "new_affine = update_affine_for_new_spacing(orig_affine, target_spacing)\n",
    "\n",
    "# ---- Save Result ----\n",
    "resampled_nib = nib.Nifti1Image(resampled_np, affine=new_affine)\n",
    "nib.save(resampled_nib, output_path)\n",
    "\n",
    "print(f\"[DONE] Saved resampled image with updated spacing to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9e9130b-f91c-4b19-8995-faea06feed84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel size: (1.0, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "img = nib.load(output_path)\n",
    "print(\"Voxel size:\", img.header.get_zooms()[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d50a4d-8c23-4bb6-813e-befdc6126d3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Resampling Size Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6017d6f-4af2-44da-b3d2-06fcc26f40e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original voxel size (mm): (0.8035714, 0.8035714, 1.1)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "img = nib.load(\"images/DUKE_001/duke_001_0001.nii.gz\")\n",
    "voxel_size = img.header.get_zooms()[:3]\n",
    "print(\"Original voxel size (mm):\", voxel_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0caa2036-d0e3-4e13-bf53-487f9fd2e482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled voxel size (mm): (0.80357134, 0.8035714, 1.1)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "img = nib.load(\"images/DUKE_001_0001_n4_corrected_denoised_resampled.nii.gz\")\n",
    "voxel_size = img.header.get_zooms()[:3]\n",
    "print(\"Resampled voxel size (mm):\", voxel_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44fdcef-618b-4e79-837c-f7e9e03549eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Check for unprocessed samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9716de2b-2eba-4ef5-94d1-8778e756f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Load CSV ----------\n",
    "csv_path = \"../train_test_splits.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Filter to only rows starting with \"DUKE\"\n",
    "train_ids = [pid for pid in df[\"train_split\"].dropna() if str(pid).startswith(\"DUKE\")]\n",
    "test_ids = [pid for pid in df[\"test_split\"].dropna() if str(pid).startswith(\"DUKE\")]\n",
    "\n",
    "expected_ids = {\n",
    "    \"train_0001\": train_ids,\n",
    "    \"test_0001\": test_ids\n",
    "}\n",
    "\n",
    "# ---------- Check which ones are missing ----------\n",
    "missing_patients = []\n",
    "\n",
    "for folder, expected_list in expected_ids.items():\n",
    "    loaded_ids = []\n",
    "    for pid in expected_list:\n",
    "        patient_folder = os.path.join(folder, pid)\n",
    "        expected_filename = f\"{pid}_0001_n4_corrected_denoised_resampled.nii.gz\"\n",
    "        full_path = os.path.join(patient_folder, expected_filename)\n",
    "        if os.path.exists(full_path):\n",
    "            loaded_ids.append(pid)\n",
    "    missing = sorted(set(expected_list) - set(loaded_ids))\n",
    "    if missing:\n",
    "        print(f\"[{folder}] Missing {len(missing)} patients:\")\n",
    "        for m in missing:\n",
    "            print(f\"  - {m}\")\n",
    "        missing_patients.extend(missing)\n",
    "\n",
    "print(f\"\\nTotal missing: {len(missing_patients)}\")\n",
    "# ---------- Save missing patient IDs to text file ----------\n",
    "output_path = \"missing_patients.txt\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    for pid in missing_patients:\n",
    "        f.write(f\"{pid}\\n\")\n",
    "\n",
    "print(f\"\\n✅ Saved missing patient IDs to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d7b21-6df5-496a-9d14-78ba5ceca581",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get sizes of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f71886-0f2a-4c72-9b7a-ccf503ad542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "base_dirs = [\"train_0001\", \"test_0001\"]\n",
    "image_shapes = []\n",
    "\n",
    "for base_dir in base_dirs:\n",
    "    print(f\"[INFO] Scanning directory: {base_dir}\")\n",
    "    for patient_id in os.listdir(base_dir):\n",
    "        patient_path = os.path.join(base_dir, patient_id)\n",
    "        if not os.path.isdir(patient_path):\n",
    "            continue\n",
    "        for file in os.listdir(patient_path):\n",
    "            if file.endswith(\"_0001_n4_corrected_denoised_resampled.nii.gz\"):\n",
    "                file_path = os.path.join(patient_path, file)\n",
    "                try:\n",
    "                    img = nib.load(file_path)\n",
    "                    shape = img.shape\n",
    "                    image_shapes.append(shape)\n",
    "                    print(f\"{file_path} => shape: {shape}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Failed to load {file_path}: {e}\")\n",
    "\n",
    "# Convert to NumPy array for analysis\n",
    "shape_array = np.array(image_shapes)\n",
    "avg_shape = np.mean(shape_array, axis=0)\n",
    "std_shape = np.std(shape_array, axis=0)\n",
    "\n",
    "print(\"\\n========== Summary ==========\")\n",
    "print(f\"Number of images: {len(image_shapes)}\")\n",
    "print(f\"Average shape: {avg_shape}\")\n",
    "print(f\"Standard deviation: {std_shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b139b-25b4-4fce-97ee-8243edf7b400",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get Size of 1 Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6a9f13a-a8ee-4bd5-b05a-0db78ef105a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: 'C:/Users/edwin/REU 2025/images/DUKE_002/duke_002_0001.nii'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nibabel\\loadsave.py:101\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'C:/Users/edwin/REU 2025/images/DUKE_002/duke_002_0001.nii'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124medwin\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mREU 2025\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDUKE_002\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mduke_002_0001.nii\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# --- Load the image ---\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m img_data \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mget_fdata()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# --- Print the shape (size in voxels) ---\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nibabel\\loadsave.py:103\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or no access: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stat_result\u001b[38;5;241m.\u001b[39mst_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ImageFileError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or no access: 'C:/Users/edwin/REU 2025/images/DUKE_002/duke_002_0001.nii'"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "# --- Set your file path here ---\n",
    "file_path = r\"C:\\Users\\edwin\\REU 2025\\images\\DUKE_002\\duke_002_0001.nii\"\n",
    "\n",
    "# --- Load the image ---\n",
    "img = nib.load(file_path)\n",
    "img_data = img.get_fdata()\n",
    "\n",
    "# --- Print the shape (size in voxels) ---\n",
    "print(f\"Image shape (z, y, x): {img_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ddf144-f3dc-426f-9898-488f194bcc57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Print Mask + Image Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f60480a5-23b8-472e-af86-89ef778d225c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Image]\n",
      "  Shape: (448, 448, 160)\n",
      "  Spacing: (0.8035714, 0.8035714, 1.1)\n",
      "[Mask]\n",
      "  Shape: (448, 448, 160)\n",
      "  Spacing: (0.8035714, 0.8035714, 1.1)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "image_path = \"images/DUKE_001/duke_001_0001.nii.gz\"\n",
    "mask_path = \"segmentations/automatic/DUKE_001.nii.gz\"\n",
    "\n",
    "# Load image\n",
    "img = nib.load(image_path)\n",
    "print(\"[Image]\")\n",
    "print(\"  Shape:\", img.shape)\n",
    "print(\"  Spacing:\", img.header.get_zooms()[:3])\n",
    "\n",
    "# Load mask\n",
    "mask = nib.load(mask_path)\n",
    "print(\"[Mask]\")\n",
    "print(\"  Shape:\", mask.shape)\n",
    "print(\"  Spacing:\", mask.header.get_zooms()[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c0aa1b-bd7e-488a-84ad-8d78276f59d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Check Range of Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b995feb-ac1d-410a-adcb-dc4124e67be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in mask: [0. 1.]\n",
      "Is binary mask: True\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Path to your mask\n",
    "mask_path = \"segmentations/automatic/DUKE_001_processed.nii.gz\"\n",
    "\n",
    "# Load mask\n",
    "mask = nib.load(mask_path).get_fdata()\n",
    "\n",
    "# Get unique values\n",
    "unique_values = np.unique(mask)\n",
    "print(f\"Unique values in mask: {unique_values}\")\n",
    "\n",
    "# Check if it's binary\n",
    "is_binary = np.array_equal(unique_values, [0, 1])\n",
    "print(\"Is binary mask:\", is_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fd780b-2912-45d8-a530-e30fcf038fa1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Count Number of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80c57868-36de-40b4-b6cb-758a40a48e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folders starting with 'DUKE': 291\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to your images directory\n",
    "images_dir = \"images\"\n",
    "\n",
    "# List all entries in the directory\n",
    "all_entries = os.listdir(images_dir)\n",
    "\n",
    "# Filter for directories starting with \"DUKE\"\n",
    "duke_folders = [\n",
    "    name for name in all_entries\n",
    "    if name.startswith(\"DUKE\") and os.path.isdir(os.path.join(images_dir, name))\n",
    "]\n",
    "\n",
    "# Count and print the number\n",
    "print(f\"Number of folders starting with 'DUKE': {len(duke_folders)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210658cc-789a-4c88-add8-0bd63ad842a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Flip One Image Along Axial Plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81c20849-d941-4d27-be90-02f7da00429d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Flipping: images/DUKE_001_0001_n4_denoised_resampled_padded.nii.gz\n",
      "[✅ SAVED] Flipped output: images/DUKE_001_0001_n4_denoised_resampled_padded_flipped_LR.nii.gz\n",
      "[INFO] Flipping: segmentations/automatic/DUKE_001_processed.nii.gz\n",
      "[✅ SAVED] Flipped output: segmentations/automatic/DUKE_001_processed_flipped_LR.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ---- Input Paths ----\n",
    "image_path = \"images/DUKE_001_0001_n4_denoised_resampled_padded.nii.gz\"\n",
    "mask_path = \"segmentations/automatic/DUKE_001_processed.nii.gz\"\n",
    "\n",
    "# ---- Output Paths ----\n",
    "flipped_image_path = image_path.replace(\".nii.gz\", \"_flipped_LR.nii.gz\")\n",
    "flipped_mask_path = mask_path.replace(\".nii.gz\", \"_flipped_LR.nii.gz\")\n",
    "\n",
    "def flip_lr(input_path, output_path):\n",
    "    print(f\"[INFO] Flipping: {input_path}\")\n",
    "    nib_img = nib.load(input_path)\n",
    "    data = nib_img.get_fdata()\n",
    "    flipped_data = np.flip(data, axis=0)  # Flip along x-axis (left-right)\n",
    "    flipped_nib = nib.Nifti1Image(flipped_data, nib_img.affine)\n",
    "    nib.save(flipped_nib, output_path)\n",
    "    print(f\"[✅ SAVED] Flipped output: {output_path}\")\n",
    "\n",
    "# ---- Flip both image and mask ----\n",
    "flip_lr(image_path, flipped_image_path)\n",
    "flip_lr(mask_path, flipped_mask_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b2129-b7ec-4c10-9ba7-594f5ab5ee22",
   "metadata": {},
   "source": [
    "## Flip All Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0592b-3f88-4c07-91e7-1d8d12a106e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# ---- Directories ----\n",
    "images_root = \"images\"\n",
    "masks_root = \"segmentations/automatic\"\n",
    "\n",
    "# ---- Utility Function ----\n",
    "def flip_lr(input_path, output_path):\n",
    "    nib_img = nib.load(input_path)\n",
    "    data = nib_img.get_fdata()\n",
    "    flipped_data = np.flip(data, axis=0)  # Flip along x-axis (left-right)\n",
    "    flipped_nib = nib.Nifti1Image(flipped_data, nib_img.affine)\n",
    "    nib.save(flipped_nib, output_path)\n",
    "    print(f\"[✅ SAVED] Flipped: {output_path}\")\n",
    "\n",
    "# ---- Main Loop ----\n",
    "all_patient_ids = sorted(os.listdir(images_root))\n",
    "\n",
    "for patient_id in all_patient_ids:\n",
    "    if not patient_id.startswith(\"DUKE\"):\n",
    "        continue\n",
    "\n",
    "    # Construct paths\n",
    "    image_path = os.path.join(images_root, patient_id, f\"{patient_id}_0001_n4_denoised_resampled_padded.nii.gz\")\n",
    "    mask_path = os.path.join(masks_root, f\"{patient_id}_processed.nii.gz\")\n",
    "\n",
    "    # Check existence\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"[SKIP] Image not found: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    if not os.path.exists(mask_path):\n",
    "        print(f\"[SKIP] Mask not found: {mask_path}\")\n",
    "        continue\n",
    "\n",
    "    # Output paths\n",
    "    flipped_image_path = image_path.replace(\".nii.gz\", \"_flipped_LR.nii.gz\")\n",
    "    flipped_mask_path = mask_path.replace(\".nii.gz\", \"_flipped_LR.nii.gz\")\n",
    "\n",
    "    print(f\"\\n[PROCESSING] {patient_id}\")\n",
    "    flip_lr(image_path, flipped_image_path)\n",
    "    flip_lr(mask_path, flipped_mask_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b0aee8-f86d-4270-961a-e1f07b85e9ec",
   "metadata": {},
   "source": [
    "## Count Classification Proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9591695-a1dc-4a51-ad23-04e543d629f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load quality scores\n",
    "quality_path = \"../preliminary_automatic_segmentations_quality_scores.csv\"\n",
    "quality_df = pd.read_csv(quality_path)\n",
    "\n",
    "# Identify all flipped image-mask pairs\n",
    "image_root = \"../images\"\n",
    "mask_root = \"../segmentations/automatic\"\n",
    "\n",
    "valid_pairs = []\n",
    "good_pairs = []\n",
    "\n",
    "# Create set of \"both good\" patient_ids\n",
    "good_ids = set(\n",
    "    quality_df[\n",
    "        (quality_df[\"expert_1_qs\"] == \"Good\") &\n",
    "        (quality_df[\"expert_2_qs\"] == \"Good\")\n",
    "    ][\"patient_id\"]\n",
    ")\n",
    "\n",
    "# Traverse through the images directory\n",
    "for patient_folder in os.listdir(image_root):\n",
    "    patient_id = patient_folder\n",
    "    image_path = os.path.join(image_root, patient_id, f\"{patient_id}_0001_n4_denoised_resampled_padded_flipped_LR.nii.gz\")\n",
    "    mask_path = os.path.join(mask_root, f\"{patient_id}_processed_flipped_LR.nii.gz\")\n",
    "\n",
    "    if os.path.isfile(image_path) and os.path.isfile(mask_path):\n",
    "        valid_pairs.append(patient_id)\n",
    "        if patient_id in good_ids:\n",
    "            good_pairs.append(patient_id)\n",
    "\n",
    "# Output results\n",
    "print(f\"Total valid image-mask pairs: {len(valid_pairs)}\")\n",
    "print(f\"Valid pairs with both expert scores 'Good': {len(good_pairs)}\")\n",
    "print(f\"Proportion: {len(good_pairs) / len(valid_pairs):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8cf6de-b7cd-44fe-aad1-3ff212c6b83c",
   "metadata": {},
   "source": [
    "## Last Processed Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414be29b-aa88-4090-b21b-8ac652103b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 'DUKE_656')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and parse the uploaded file to identify the highest index mentioned\n",
    "file_path = \"preprocess_12184073.out\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Extract all lines containing index information\n",
    "import re\n",
    "index_patient_pairs = []\n",
    "for line in lines:\n",
    "    match = re.search(r\"\\[INDEX\\] Processing patient index (\\d+) \\((DUKE_\\d+)\\)\", line)\n",
    "    if match:\n",
    "        index = int(match.group(1))\n",
    "        patient_id = match.group(2)\n",
    "        index_patient_pairs.append((index, patient_id))\n",
    "\n",
    "# Get the pair with the highest index\n",
    "highest_pair = max(index_patient_pairs, key=lambda x: x[0]) if index_patient_pairs else None\n",
    "highest_pair\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79dc6f3-586a-4d3e-a7b4-ff0ec5244b16",
   "metadata": {},
   "source": [
    "### N4 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf3bce-e3f2-4fcf-b802-d25eacf0d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# ---- Configuration ----\n",
    "patient_id = \"DUKE_001\"\n",
    "images_root = \"../images\"\n",
    "preprocessed_root = \"../preprocessed\"\n",
    "output_dir = os.path.join(preprocessed_root, patient_id, \"n4_test\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def n4_bias_correction_with_metadata(nib_image):\n",
    "    print(\"[STEP] Running N4 bias correction...\")\n",
    "\n",
    "    # Convert nibabel image to SimpleITK image\n",
    "    image_np = nib_image.get_fdata().astype(np.float32)\n",
    "    sitk_image = sitk.GetImageFromArray(image_np)\n",
    "\n",
    "    # Extract spatial metadata from nibabel\n",
    "    zooms = tuple(float(z) for z in nib_image.header.get_zooms()[:3])\n",
    "    sitk_image.SetSpacing(zooms)\n",
    "    sitk_image.SetOrigin((0.0, 0.0, 0.0))  # origin is arbitrary if not stored; safe default\n",
    "    sitk_image.SetDirection((1.0, 0.0, 0.0,\n",
    "                             0.0, 1.0, 0.0,\n",
    "                             0.0, 0.0, 1.0))  # assume axial acquisition\n",
    "\n",
    "    mask_image = sitk.Cast(sitk_image > 0, sitk.sitkUInt8)\n",
    "    corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    corrected = corrector.Execute(sitk_image, mask_image)\n",
    "\n",
    "    print(\"[DONE] N4 bias correction complete.\")\n",
    "    return sitk.GetArrayFromImage(corrected)\n",
    "\n",
    "\n",
    "# ---- Process DUKE_001 ----\n",
    "patient_folder = os.path.join(images_root, patient_id)\n",
    "for fname in os.listdir(patient_folder):\n",
    "    if fname.startswith(\"DUKE_\") and fname.endswith(\"0001.nii.gz\"):\n",
    "        input_path = os.path.join(patient_folder, fname)\n",
    "        print(f\"[PROCESSING] {input_path}\", flush=True)\n",
    "\n",
    "        # Load and correct\n",
    "        img_nib = nib.load(input_path)\n",
    "        img_n4 = n4_bias_correction_with_metadata(img_nib)\n",
    "\n",
    "\n",
    "        # Save output\n",
    "        output_path = os.path.join(output_dir, \"n4.nii.gz\")\n",
    "        nib.save(nib.Nifti1Image(img_n4, img_nib.affine), output_path)\n",
    "        print(f\"[✅ SAVED] N4 corrected image to {output_path}\")\n",
    "        break  # Only process one image\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
